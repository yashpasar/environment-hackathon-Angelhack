{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your work here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good luck :]\n",
    "# import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt #Visualization\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data pre-processing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler # transforming data(normalize/standardize)\n",
    "from pathlib import Path\n",
    "import time # wall time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20007, 2112)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npTrainMatrix =np.load('data/2018-01-01__2019-01-01__NConservatory_npWeekdayAllOrderedSensorsTimeRef.npy')\n",
    "npTrainMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9898, 2112)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch, torch.nn as nn, time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import joblib\n",
    "trainingData=npTrainMatrix\n",
    "test_data = joblib.load('./test_data/test_dataset_2019.numpy')\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoaderTrain = DataLoader( trainingData.astype('float32'), \n",
    "                              batch_size = 18, \n",
    "                              shuffle = True )\n",
    "\n",
    "dataLoaderTest = DataLoader( test_data.astype('float32'), \n",
    "                             batch_size = 18, \n",
    "                             shuffle = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputDimensionality = trainingData.shape[1]\n",
    "encoderModel = nn.Sequential(\n",
    "    nn.Linear(inputDimensionality, inputDimensionality//2), nn.ELU(),\n",
    "    nn.Linear(inputDimensionality//2, inputDimensionality//4), nn.ELU(),\n",
    "    nn.Linear(inputDimensionality//4, inputDimensionality//10), nn.ELU()\n",
    ")\n",
    "decoderModel = nn.Sequential(\n",
    "    nn.Linear(inputDimensionality//10, inputDimensionality//4), nn.ELU(),\n",
    "    nn.Linear(inputDimensionality//4, inputDimensionality//2), nn.ELU(),\n",
    "    nn.Linear(inputDimensionality//2, inputDimensionality)\n",
    ")\n",
    "\n",
    "# combine\n",
    "list_of_layers = list(encoderModel.children())\n",
    "list_of_layers.extend(list(decoderModel.children()))\n",
    "model = nn.Sequential (*list_of_layers)\n",
    "\n",
    "# sanity check\n",
    "list( nn.Sequential(*list(model.children())[0:6]).parameters() ) == list(encoderModel.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetDeviceCPU = torch.device('cpu')\n",
    "targetDeviceGPU = torch.device('cuda:0') \n",
    "targetDevice = targetDeviceGPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model ( model, dataLoader, targetDevice, nEpochs = 10 ):\n",
    "\n",
    "    model = model.to( targetDevice )\n",
    "    \n",
    "    lossFunction = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam( model.parameters() )\n",
    "    lossHistory = []\n",
    "    \n",
    "    # training loop    \n",
    "    for iEpoch in range(nEpochs):   \n",
    "        cumulativeLoss = 0\n",
    "        for i, iInputBatch in enumerate( dataLoader ):\n",
    "            \n",
    "            # move batch data to target training device [ cpu or gpu ]\n",
    "            iInputBatch = iInputBatch.to( targetDevice )\n",
    "            \n",
    "            # zero/reset the parameter gradient buffers to avoid accumulation [ usually accumulation is necessary for temporally unrolled networks ]\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # generate predictions/reconstructions\n",
    "            predictions = model.forward(iInputBatch)\n",
    "\n",
    "            # compute error \n",
    "            loss = lossFunction( predictions, iInputBatch )\n",
    "            cumulativeLoss += loss.item() # gets scaler value held in the loss tensor\n",
    "            \n",
    "            # compute gradients by propagating the error backward through the model/graph\n",
    "            loss.backward()\n",
    "\n",
    "            # apply gradients to update model parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "        print( 'epoch {} of {} -- avg batch loss: {}'.format(iEpoch, nEpochs, cumulativeLoss))\n",
    "        \n",
    "        lossHistory += [ cumulativeLoss ]\n",
    "    return model, lossHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 of 10 -- avg batch loss: 102.48679767549038\n",
      "epoch 1 of 10 -- avg batch loss: 66.01168463379145\n",
      "epoch 2 of 10 -- avg batch loss: 58.15719835087657\n",
      "epoch 3 of 10 -- avg batch loss: 54.16476408392191\n",
      "epoch 4 of 10 -- avg batch loss: 51.704566083848476\n",
      "epoch 5 of 10 -- avg batch loss: 49.37479520216584\n",
      "epoch 6 of 10 -- avg batch loss: 47.166845094412565\n",
      "epoch 7 of 10 -- avg batch loss: 45.785805366933346\n",
      "epoch 8 of 10 -- avg batch loss: 44.381768049672246\n",
      "epoch 9 of 10 -- avg batch loss: 43.69910876825452\n",
      "elapsed time : 75.36153864860535 \n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "\n",
    "model, lossHistory = train_model( model, dataLoaderTrain, targetDevice, nEpochs = 10 )\n",
    "\n",
    "print('elapsed time : {} '.format(time.time() - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossHistory)\n",
    "plt.title('Loss History'); plt.xlabel('epoch'); plt.ylabel('cumulative loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model ( model, dataLoader, targetDevice):\n",
    "    \n",
    "    predictions, losses = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        model=model.eval()\n",
    "        \n",
    "        for seq_true in iter(dataLoader):\n",
    "\n",
    "            \n",
    "            reconstruction = model.forward(seq_true.to(targetDevice))\n",
    "            \n",
    "            sampleNumpy = seq_true.numpy()\n",
    "            reconstructionNumpy = reconstruction.data.cpu().numpy()\n",
    "\n",
    "            error = np.sqrt( (reconstructionNumpy - sampleNumpy)**2 )\n",
    "            \n",
    "            losses.append(error)\n",
    "            predictions.append(reconstructionNumpy.flatten())\n",
    "\n",
    "            \n",
    "            \n",
    "    return predictions,losses\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,pred_losses=evaluate_model( model, dataLoaderTest, targetDeviceGPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct = sum(l >= 6250 for l in pred_losses)\n",
    "# print(f'Correct predictions: {correct}/{len(dataLoaderTest)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "count=0\n",
    "for days in pred_losses:\n",
    "    for day in days:\n",
    "        c=0\n",
    "        for item in day[0:1536]:\n",
    "            if item > 0.5:\n",
    "                c+=1\n",
    "        a.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=[]\n",
    "for i,v in enumerate(a):\n",
    "    submission.append([i+1,v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = {}\n",
    "for i in range(len(a)):\n",
    "    di[i+1] = a[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('submission.txt', 'w') as fp:\n",
    "    for p in di.items():\n",
    "        fp.write(\"%s,%s\\n\" % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "w = csv.writer(open(\"submission.csv\", \"w\"))\n",
    "for key, val in di.items():\n",
    "    w.writerow([key, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_submission ( filename ):\n",
    "    dayIndicators = [] \n",
    "    startSampleIndicators = []\n",
    "    lineCount = 0 \n",
    "    with open(filename) as submission_text:\n",
    "        line = submission_text.readline()        \n",
    "        while line:\n",
    "            if lineCount > 200: break\n",
    "                    \n",
    "            dayIndicators += [line.split(',')[0].strip()]\n",
    "            startSampleIndicators += [line.split(',')[1].strip()]\n",
    "            \n",
    "            print( f'parsing line#{lineCount}: {line}' )\n",
    "            line = submission_text.readline()\n",
    "            lineCount += 1\n",
    "            \n",
    "    return dayIndicators, startSampleIndicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing line#0: 1,49\n",
      "\n",
      "parsing line#1: 2,18\n",
      "\n",
      "parsing line#2: 3,77\n",
      "\n",
      "parsing line#3: 4,80\n",
      "\n",
      "parsing line#4: 5,65\n",
      "\n",
      "parsing line#5: 6,70\n",
      "\n",
      "parsing line#6: 7,83\n",
      "\n",
      "parsing line#7: 8,467\n",
      "\n",
      "parsing line#8: 9,126\n",
      "\n",
      "parsing line#9: 10,61\n",
      "\n",
      "parsing line#10: 11,61\n",
      "\n",
      "parsing line#11: 12,96\n",
      "\n",
      "parsing line#12: 13,155\n",
      "\n",
      "parsing line#13: 14,206\n",
      "\n",
      "parsing line#14: 15,64\n",
      "\n",
      "parsing line#15: 16,98\n",
      "\n",
      "parsing line#16: 17,74\n",
      "\n",
      "parsing line#17: 18,135\n",
      "\n",
      "parsing line#18: 19,53\n",
      "\n",
      "parsing line#19: 20,39\n",
      "\n",
      "parsing line#20: 21,113\n",
      "\n",
      "parsing line#21: 22,116\n",
      "\n",
      "parsing line#22: 23,74\n",
      "\n",
      "parsing line#23: 24,89\n",
      "\n",
      "parsing line#24: 25,87\n",
      "\n",
      "parsing line#25: 26,160\n",
      "\n",
      "parsing line#26: 27,53\n",
      "\n",
      "parsing line#27: 28,89\n",
      "\n",
      "parsing line#28: 29,51\n",
      "\n",
      "parsing line#29: 30,71\n",
      "\n",
      "parsing line#30: 31,91\n",
      "\n",
      "parsing line#31: 32,43\n",
      "\n",
      "parsing line#32: 33,76\n",
      "\n",
      "parsing line#33: 34,40\n",
      "\n",
      "parsing line#34: 35,71\n",
      "\n",
      "parsing line#35: 36,57\n",
      "\n",
      "parsing line#36: 37,71\n",
      "\n",
      "parsing line#37: 38,61\n",
      "\n",
      "parsing line#38: 39,65\n",
      "\n",
      "parsing line#39: 40,100\n",
      "\n",
      "parsing line#40: 41,326\n",
      "\n",
      "parsing line#41: 42,90\n",
      "\n",
      "parsing line#42: 43,125\n",
      "\n",
      "parsing line#43: 44,103\n",
      "\n",
      "parsing line#44: 45,293\n",
      "\n",
      "parsing line#45: 46,392\n",
      "\n",
      "parsing line#46: 47,67\n",
      "\n",
      "parsing line#47: 48,105\n",
      "\n",
      "parsing line#48: 49,154\n",
      "\n",
      "parsing line#49: 50,179\n",
      "\n",
      "parsing line#50: 51,87\n",
      "\n",
      "parsing line#51: 52,99\n",
      "\n",
      "parsing line#52: 53,109\n",
      "\n",
      "parsing line#53: 54,114\n",
      "\n",
      "parsing line#54: 55,307\n",
      "\n",
      "parsing line#55: 56,506\n",
      "\n",
      "parsing line#56: 57,90\n",
      "\n",
      "parsing line#57: 58,97\n",
      "\n",
      "parsing line#58: 59,355\n",
      "\n",
      "parsing line#59: 60,64\n",
      "\n",
      "parsing line#60: 61,69\n",
      "\n",
      "parsing line#61: 62,61\n",
      "\n",
      "parsing line#62: 63,138\n",
      "\n",
      "parsing line#63: 64,78\n",
      "\n",
      "parsing line#64: 65,75\n",
      "\n",
      "parsing line#65: 66,89\n",
      "\n",
      "parsing line#66: 67,80\n",
      "\n",
      "parsing line#67: 68,61\n",
      "\n",
      "parsing line#68: 69,40\n",
      "\n",
      "parsing line#69: 70,76\n",
      "\n",
      "parsing line#70: 71,45\n",
      "\n",
      "parsing line#71: 72,65\n",
      "\n",
      "parsing line#72: 73,55\n",
      "\n",
      "parsing line#73: 74,39\n",
      "\n",
      "parsing line#74: 75,67\n",
      "\n",
      "parsing line#75: 76,82\n",
      "\n",
      "parsing line#76: 77,101\n",
      "\n",
      "parsing line#77: 78,90\n",
      "\n",
      "parsing line#78: 79,46\n",
      "\n",
      "parsing line#79: 80,67\n",
      "\n",
      "parsing line#80: 81,68\n",
      "\n",
      "parsing line#81: 82,64\n",
      "\n",
      "parsing line#82: 83,76\n",
      "\n",
      "parsing line#83: 84,72\n",
      "\n",
      "parsing line#84: 85,49\n",
      "\n",
      "parsing line#85: 86,71\n",
      "\n",
      "parsing line#86: 87,307\n",
      "\n",
      "parsing line#87: 88,367\n",
      "\n",
      "parsing line#88: 89,112\n",
      "\n",
      "parsing line#89: 90,61\n",
      "\n",
      "parsing line#90: 91,105\n",
      "\n",
      "parsing line#91: 92,66\n",
      "\n",
      "parsing line#92: 93,86\n",
      "\n",
      "parsing line#93: 94,57\n",
      "\n",
      "parsing line#94: 95,30\n",
      "\n",
      "parsing line#95: 96,118\n",
      "\n",
      "parsing line#96: 97,450\n",
      "\n",
      "parsing line#97: 98,96\n",
      "\n",
      "parsing line#98: 99,79\n",
      "\n",
      "parsing line#99: 100,83\n",
      "\n",
      "parsing line#100: 101,205\n",
      "\n",
      "parsing line#101: 102,249\n",
      "\n",
      "parsing line#102: 103,114\n",
      "\n",
      "parsing line#103: 104,222\n",
      "\n",
      "parsing line#104: 105,86\n",
      "\n",
      "parsing line#105: 106,80\n",
      "\n",
      "parsing line#106: 107,181\n",
      "\n",
      "parsing line#107: 108,169\n",
      "\n",
      "parsing line#108: 109,64\n",
      "\n",
      "parsing line#109: 110,37\n",
      "\n",
      "parsing line#110: 111,52\n",
      "\n",
      "parsing line#111: 112,47\n",
      "\n",
      "parsing line#112: 113,493\n",
      "\n",
      "parsing line#113: 114,49\n",
      "\n",
      "parsing line#114: 115,74\n",
      "\n",
      "parsing line#115: 116,231\n",
      "\n",
      "parsing line#116: 117,53\n",
      "\n",
      "parsing line#117: 118,83\n",
      "\n",
      "parsing line#118: 119,90\n",
      "\n",
      "parsing line#119: 120,29\n",
      "\n",
      "parsing line#120: 121,77\n",
      "\n",
      "parsing line#121: 122,266\n",
      "\n",
      "parsing line#122: 123,138\n",
      "\n",
      "parsing line#123: 124,80\n",
      "\n",
      "parsing line#124: 125,56\n",
      "\n",
      "parsing line#125: 126,75\n",
      "\n",
      "parsing line#126: 127,128\n",
      "\n",
      "parsing line#127: 128,82\n",
      "\n",
      "parsing line#128: 129,47\n",
      "\n",
      "parsing line#129: 130,61\n",
      "\n",
      "parsing line#130: 131,44\n",
      "\n",
      "parsing line#131: 132,80\n",
      "\n",
      "parsing line#132: 133,455\n",
      "\n",
      "parsing line#133: 134,29\n",
      "\n",
      "parsing line#134: 135,57\n",
      "\n",
      "parsing line#135: 136,81\n",
      "\n",
      "parsing line#136: 137,204\n",
      "\n",
      "parsing line#137: 138,66\n",
      "\n",
      "parsing line#138: 139,39\n",
      "\n",
      "parsing line#139: 140,70\n",
      "\n",
      "parsing line#140: 141,122\n",
      "\n",
      "parsing line#141: 142,59\n",
      "\n",
      "parsing line#142: 143,115\n",
      "\n",
      "parsing line#143: 144,71\n",
      "\n",
      "parsing line#144: 145,76\n",
      "\n",
      "parsing line#145: 146,51\n",
      "\n",
      "parsing line#146: 147,66\n",
      "\n",
      "parsing line#147: 148,108\n",
      "\n",
      "parsing line#148: 149,25\n",
      "\n",
      "parsing line#149: 150,102\n",
      "\n",
      "parsing line#150: 151,393\n",
      "\n",
      "parsing line#151: 152,429\n",
      "\n",
      "parsing line#152: 153,199\n",
      "\n",
      "parsing line#153: 154,202\n",
      "\n",
      "parsing line#154: 155,87\n",
      "\n",
      "parsing line#155: 156,135\n",
      "\n",
      "parsing line#156: 157,110\n",
      "\n",
      "parsing line#157: 158,67\n",
      "\n",
      "parsing line#158: 159,90\n",
      "\n",
      "parsing line#159: 160,130\n",
      "\n",
      "parsing line#160: 161,75\n",
      "\n",
      "parsing line#161: 162,352\n",
      "\n",
      "parsing line#162: 163,106\n",
      "\n",
      "parsing line#163: 164,227\n",
      "\n",
      "parsing line#164: 165,95\n",
      "\n",
      "parsing line#165: 166,274\n",
      "\n",
      "parsing line#166: 167,92\n",
      "\n",
      "parsing line#167: 168,65\n",
      "\n",
      "parsing line#168: 169,73\n",
      "\n",
      "parsing line#169: 170,360\n",
      "\n",
      "parsing line#170: 171,134\n",
      "\n",
      "parsing line#171: 172,166\n",
      "\n",
      "parsing line#172: 173,33\n",
      "\n",
      "parsing line#173: 174,72\n",
      "\n",
      "parsing line#174: 175,477\n",
      "\n",
      "parsing line#175: 176,73\n",
      "\n",
      "parsing line#176: 177,341\n",
      "\n",
      "parsing line#177: 178,70\n",
      "\n",
      "parsing line#178: 179,85\n",
      "\n",
      "parsing line#179: 180,145\n",
      "\n",
      "parsing line#180: 181,89\n",
      "\n",
      "parsing line#181: 182,56\n",
      "\n",
      "parsing line#182: 183,56\n",
      "\n",
      "parsing line#183: 184,84\n",
      "\n",
      "parsing line#184: 185,130\n",
      "\n",
      "parsing line#185: 186,80\n",
      "\n",
      "parsing line#186: 187,371\n",
      "\n",
      "parsing line#187: 188,75\n",
      "\n",
      "parsing line#188: 189,68\n",
      "\n",
      "parsing line#189: 190,93\n",
      "\n",
      "parsing line#190: 191,102\n",
      "\n",
      "parsing line#191: 192,447\n",
      "\n",
      "parsing line#192: 193,374\n",
      "\n",
      "parsing line#193: 194,392\n",
      "\n",
      "parsing line#194: 195,58\n",
      "\n",
      "parsing line#195: 196,290\n",
      "\n",
      "parsing line#196: 197,109\n",
      "\n",
      "parsing line#197: 198,104\n",
      "\n",
      "parsing line#198: 199,440\n",
      "\n",
      "parsing line#199: 200,90\n",
      "\n",
      "parsing line#200: 201,74\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['1',\n",
       "  '2',\n",
       "  '3',\n",
       "  '4',\n",
       "  '5',\n",
       "  '6',\n",
       "  '7',\n",
       "  '8',\n",
       "  '9',\n",
       "  '10',\n",
       "  '11',\n",
       "  '12',\n",
       "  '13',\n",
       "  '14',\n",
       "  '15',\n",
       "  '16',\n",
       "  '17',\n",
       "  '18',\n",
       "  '19',\n",
       "  '20',\n",
       "  '21',\n",
       "  '22',\n",
       "  '23',\n",
       "  '24',\n",
       "  '25',\n",
       "  '26',\n",
       "  '27',\n",
       "  '28',\n",
       "  '29',\n",
       "  '30',\n",
       "  '31',\n",
       "  '32',\n",
       "  '33',\n",
       "  '34',\n",
       "  '35',\n",
       "  '36',\n",
       "  '37',\n",
       "  '38',\n",
       "  '39',\n",
       "  '40',\n",
       "  '41',\n",
       "  '42',\n",
       "  '43',\n",
       "  '44',\n",
       "  '45',\n",
       "  '46',\n",
       "  '47',\n",
       "  '48',\n",
       "  '49',\n",
       "  '50',\n",
       "  '51',\n",
       "  '52',\n",
       "  '53',\n",
       "  '54',\n",
       "  '55',\n",
       "  '56',\n",
       "  '57',\n",
       "  '58',\n",
       "  '59',\n",
       "  '60',\n",
       "  '61',\n",
       "  '62',\n",
       "  '63',\n",
       "  '64',\n",
       "  '65',\n",
       "  '66',\n",
       "  '67',\n",
       "  '68',\n",
       "  '69',\n",
       "  '70',\n",
       "  '71',\n",
       "  '72',\n",
       "  '73',\n",
       "  '74',\n",
       "  '75',\n",
       "  '76',\n",
       "  '77',\n",
       "  '78',\n",
       "  '79',\n",
       "  '80',\n",
       "  '81',\n",
       "  '82',\n",
       "  '83',\n",
       "  '84',\n",
       "  '85',\n",
       "  '86',\n",
       "  '87',\n",
       "  '88',\n",
       "  '89',\n",
       "  '90',\n",
       "  '91',\n",
       "  '92',\n",
       "  '93',\n",
       "  '94',\n",
       "  '95',\n",
       "  '96',\n",
       "  '97',\n",
       "  '98',\n",
       "  '99',\n",
       "  '100',\n",
       "  '101',\n",
       "  '102',\n",
       "  '103',\n",
       "  '104',\n",
       "  '105',\n",
       "  '106',\n",
       "  '107',\n",
       "  '108',\n",
       "  '109',\n",
       "  '110',\n",
       "  '111',\n",
       "  '112',\n",
       "  '113',\n",
       "  '114',\n",
       "  '115',\n",
       "  '116',\n",
       "  '117',\n",
       "  '118',\n",
       "  '119',\n",
       "  '120',\n",
       "  '121',\n",
       "  '122',\n",
       "  '123',\n",
       "  '124',\n",
       "  '125',\n",
       "  '126',\n",
       "  '127',\n",
       "  '128',\n",
       "  '129',\n",
       "  '130',\n",
       "  '131',\n",
       "  '132',\n",
       "  '133',\n",
       "  '134',\n",
       "  '135',\n",
       "  '136',\n",
       "  '137',\n",
       "  '138',\n",
       "  '139',\n",
       "  '140',\n",
       "  '141',\n",
       "  '142',\n",
       "  '143',\n",
       "  '144',\n",
       "  '145',\n",
       "  '146',\n",
       "  '147',\n",
       "  '148',\n",
       "  '149',\n",
       "  '150',\n",
       "  '151',\n",
       "  '152',\n",
       "  '153',\n",
       "  '154',\n",
       "  '155',\n",
       "  '156',\n",
       "  '157',\n",
       "  '158',\n",
       "  '159',\n",
       "  '160',\n",
       "  '161',\n",
       "  '162',\n",
       "  '163',\n",
       "  '164',\n",
       "  '165',\n",
       "  '166',\n",
       "  '167',\n",
       "  '168',\n",
       "  '169',\n",
       "  '170',\n",
       "  '171',\n",
       "  '172',\n",
       "  '173',\n",
       "  '174',\n",
       "  '175',\n",
       "  '176',\n",
       "  '177',\n",
       "  '178',\n",
       "  '179',\n",
       "  '180',\n",
       "  '181',\n",
       "  '182',\n",
       "  '183',\n",
       "  '184',\n",
       "  '185',\n",
       "  '186',\n",
       "  '187',\n",
       "  '188',\n",
       "  '189',\n",
       "  '190',\n",
       "  '191',\n",
       "  '192',\n",
       "  '193',\n",
       "  '194',\n",
       "  '195',\n",
       "  '196',\n",
       "  '197',\n",
       "  '198',\n",
       "  '199',\n",
       "  '200',\n",
       "  '201'],\n",
       " ['49',\n",
       "  '18',\n",
       "  '77',\n",
       "  '80',\n",
       "  '65',\n",
       "  '70',\n",
       "  '83',\n",
       "  '467',\n",
       "  '126',\n",
       "  '61',\n",
       "  '61',\n",
       "  '96',\n",
       "  '155',\n",
       "  '206',\n",
       "  '64',\n",
       "  '98',\n",
       "  '74',\n",
       "  '135',\n",
       "  '53',\n",
       "  '39',\n",
       "  '113',\n",
       "  '116',\n",
       "  '74',\n",
       "  '89',\n",
       "  '87',\n",
       "  '160',\n",
       "  '53',\n",
       "  '89',\n",
       "  '51',\n",
       "  '71',\n",
       "  '91',\n",
       "  '43',\n",
       "  '76',\n",
       "  '40',\n",
       "  '71',\n",
       "  '57',\n",
       "  '71',\n",
       "  '61',\n",
       "  '65',\n",
       "  '100',\n",
       "  '326',\n",
       "  '90',\n",
       "  '125',\n",
       "  '103',\n",
       "  '293',\n",
       "  '392',\n",
       "  '67',\n",
       "  '105',\n",
       "  '154',\n",
       "  '179',\n",
       "  '87',\n",
       "  '99',\n",
       "  '109',\n",
       "  '114',\n",
       "  '307',\n",
       "  '506',\n",
       "  '90',\n",
       "  '97',\n",
       "  '355',\n",
       "  '64',\n",
       "  '69',\n",
       "  '61',\n",
       "  '138',\n",
       "  '78',\n",
       "  '75',\n",
       "  '89',\n",
       "  '80',\n",
       "  '61',\n",
       "  '40',\n",
       "  '76',\n",
       "  '45',\n",
       "  '65',\n",
       "  '55',\n",
       "  '39',\n",
       "  '67',\n",
       "  '82',\n",
       "  '101',\n",
       "  '90',\n",
       "  '46',\n",
       "  '67',\n",
       "  '68',\n",
       "  '64',\n",
       "  '76',\n",
       "  '72',\n",
       "  '49',\n",
       "  '71',\n",
       "  '307',\n",
       "  '367',\n",
       "  '112',\n",
       "  '61',\n",
       "  '105',\n",
       "  '66',\n",
       "  '86',\n",
       "  '57',\n",
       "  '30',\n",
       "  '118',\n",
       "  '450',\n",
       "  '96',\n",
       "  '79',\n",
       "  '83',\n",
       "  '205',\n",
       "  '249',\n",
       "  '114',\n",
       "  '222',\n",
       "  '86',\n",
       "  '80',\n",
       "  '181',\n",
       "  '169',\n",
       "  '64',\n",
       "  '37',\n",
       "  '52',\n",
       "  '47',\n",
       "  '493',\n",
       "  '49',\n",
       "  '74',\n",
       "  '231',\n",
       "  '53',\n",
       "  '83',\n",
       "  '90',\n",
       "  '29',\n",
       "  '77',\n",
       "  '266',\n",
       "  '138',\n",
       "  '80',\n",
       "  '56',\n",
       "  '75',\n",
       "  '128',\n",
       "  '82',\n",
       "  '47',\n",
       "  '61',\n",
       "  '44',\n",
       "  '80',\n",
       "  '455',\n",
       "  '29',\n",
       "  '57',\n",
       "  '81',\n",
       "  '204',\n",
       "  '66',\n",
       "  '39',\n",
       "  '70',\n",
       "  '122',\n",
       "  '59',\n",
       "  '115',\n",
       "  '71',\n",
       "  '76',\n",
       "  '51',\n",
       "  '66',\n",
       "  '108',\n",
       "  '25',\n",
       "  '102',\n",
       "  '393',\n",
       "  '429',\n",
       "  '199',\n",
       "  '202',\n",
       "  '87',\n",
       "  '135',\n",
       "  '110',\n",
       "  '67',\n",
       "  '90',\n",
       "  '130',\n",
       "  '75',\n",
       "  '352',\n",
       "  '106',\n",
       "  '227',\n",
       "  '95',\n",
       "  '274',\n",
       "  '92',\n",
       "  '65',\n",
       "  '73',\n",
       "  '360',\n",
       "  '134',\n",
       "  '166',\n",
       "  '33',\n",
       "  '72',\n",
       "  '477',\n",
       "  '73',\n",
       "  '341',\n",
       "  '70',\n",
       "  '85',\n",
       "  '145',\n",
       "  '89',\n",
       "  '56',\n",
       "  '56',\n",
       "  '84',\n",
       "  '130',\n",
       "  '80',\n",
       "  '371',\n",
       "  '75',\n",
       "  '68',\n",
       "  '93',\n",
       "  '102',\n",
       "  '447',\n",
       "  '374',\n",
       "  '392',\n",
       "  '58',\n",
       "  '290',\n",
       "  '109',\n",
       "  '104',\n",
       "  '440',\n",
       "  '90',\n",
       "  '74'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_submission ( 'submission.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
